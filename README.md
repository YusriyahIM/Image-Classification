This Project performs the following steps:

1.  **Setup and Imports**: Imports necessary libraries for file system operations, data manipulation, image processing, machine learning (TensorFlow/Keras), and visualization. It also includes shell commands to install required libraries and print version information.
2.  **Dataset Download and Preparation**:
    *   Configures Kaggle credentials to download the "fruits" dataset.
    *   Downloads and unzips the dataset.
    *   Defines paths for the training, test, and validation sets from the downloaded dataset.
    *   Merges the training, validation, and test sets into a single directory named `fruits`.
3.  **Data Exploration**:
    *   Walks through the merged dataset directory to collect file paths and labels, storing them in a pandas DataFrame.
    *   Displays example images from the first 9 unique classes found in the dataset, showing image dimensions.
    *   Prints the count of images per class in the merged dataset.
4.  **Data Preprocessing**:
    *   Selects a subset of 23 specific fruit and vegetable classes for the project to meet a minimum image count requirement.
    *   Counts the images within these target classes in the merged dataset and prints the counts.
    *   Copies only the folders corresponding to the target classes from the merged `fruits` directory into a new directory named `dataset`.
    *   Displays example images from the selected classes in the newly created `dataset` directory.
    *   Splits the `dataset` directory into `train` and `test` subdirectories with an 80/20 ratio, moving the image files accordingly.
    *   Deletes any folders in the `dataset` directory that are not `train` or `test`.
5.  **Model Building and Training**:
    *   Uses `ImageDataGenerator` to set up data augmentation (rescaling, zooming, horizontal flipping) for the training set and only rescaling for the test set.
    *   Creates image data generators (`train_generator` and `test_generator`) to load and preprocess images in batches for training and validation.
    *   Displays the class indices mapping generated by the `train_generator`.
    *   Loads a pre-trained `MobileNetV2` model (excluding the top classification layer) and freezes its weights.
    *   Builds a Sequential model on top of the pre-trained `MobileNetV2`, adding convolutional layers, pooling layers, a flatten layer, dropout, and dense layers (including a final output layer with 23 units for the selected classes).
    *   Compiles the model using the Adam optimizer and categorical crossentropy loss.
    *   Sets up `ModelCheckpoint` to save the best model based on validation loss and `EarlyStopping` to stop training if validation accuracy does not improve significantly.
    *   Trains the model for 10 epochs using the generators, validating on the test data.
6.  **Evaluation and Visualization**:
    *   Defines a function `plot_training_history` to visualize the training and validation accuracy and loss over epochs using Matplotlib.
    *   Calls the function to plot the training history of the trained model.
7.  **Model Conversion**:
    *   Saves the trained Keras model in `.h5` format.
    *   Uses `tensorflowjs_converter` to convert the `.h5` model to TensorFlow.js format.
    *   Saves the model in TensorFlow SavedModel format.
    *   Converts the `.h5` model to TensorFlow Lite (`.tflite`) format and saves it.
    *   Creates a simple text file named `label.txt` (content: 
    apple_golden_3
    apple_red_1
    apple_rotten_1
    Avocado Green 1
    Banana 3
    Beans 1
    Blackberrie 1
    Cabbage red 1
    cabbage_white_1
    Cactus fruit red 1
    Caju seed 1
    carrot_1
    Cherimoya 1
    Cherry Rainier 3
    Cherry Wax Red 2
    Cucumber 5
    eggplant_long_1
    Gooseberry 1
    pear_3
    Pistachio 1
    Quince 4
    Tomato Cherry Maroon 1
    zucchini_1).
    *   Zips the `models` and `tfjs_model` directories.
    *   Generates a `requirements.txt` file listing the installed Python packages.
8.  **Inference**:
    *   Defines functions to load and preprocess an image and to make a prediction on a single image using the trained model.
    *   Retrieves one random image path from each class in the test set.
    *   Iterates through these sample images, performs inference, prints the predicted class and confidence, and displays the image with the prediction title.